# ğŸ–¼ï¸ Image Caption Detection using CLIP

Unlock intelligent image understanding with **Image Caption Detection using CLIP** â€“ a visually rich and AI-powered web app built using **Streamlit**, **OpenAI's CLIP model**, and **PyTorch**. Upload an image and discover the best-matching captions from a large set of creative descriptions.

## ğŸš€ Live Demo

Easily deploy on **Google Colab** and access via **ngrok**.
ğŸ”— *https://b7e3-34-126-93-160.ngrok-free.app/*

---

## ğŸ“¸ Features

* âš¡ **CLIP-powered caption similarity** using OpenAI's `clip-vit-base-patch32` model
* ğŸ” Upload **multiple images** at once
* ğŸ§  Smart caption ranking based on **cosine similarity**
* ğŸ§¾ **Download matching captions** as CSV
* ğŸŒ Instant access using **ngrok tunnel**
* ğŸ’» **Google Colab** and **Streamlit** compatible

---

## ğŸ§° Tech Stack

* Python ğŸ
* [Streamlit](https://streamlit.io/) â€“ interactive web UI
* [Transformers by Hugging Face](https://huggingface.co/docs/transformers/index)
* [PyTorch](https://pytorch.org/) â€“ deep learning backend
* [CLIP Model](https://huggingface.co/openai/clip-vit-base-patch32)
* [ngrok](https://ngrok.com/) â€“ to expose local Streamlit app to the web
* [Google Colab](https://colab.research.google.com/) â€“ cloud development

---

## ğŸ§ª How It Works

1. The uploaded image is processed using the CLIP model to extract **image features**.
2. Predefined **candidate captions** are embedded into **text features** using the same model.
3. Cosine similarity is computed between image and text features.
4. Captions are ranked from most to least relevant based on similarity.

---

## ğŸ§¾ Example Captions

* "A moment of bliss."
* "Natureâ€™s silent poetry."
* "The taste of wanderlust."
* "Confidence looks good on me."

> More than **100+ creative and poetic captions** included for diverse scenarios like travel, nature, emotions, and lifestyle!

---

## ğŸ› ï¸ How to Run in Google Colab

1. Upload `app.py` to your Colab session.
2. Set your `NGROK_AUTH_TOKEN` in environment:

   ```python
   import os  
   os.environ["NGROK_AUTH_TOKEN"] = "your_ngrok_token_here"
   ```
3. Run `app.py`:

   ```python
   !streamlit run app.py &
   ```
4. Follow the ngrok public URL to access your live app.

---

## ğŸ“‚ Project Structure

```
ğŸ“ Image-Caption-Detection
â”‚
â”œâ”€â”€ app.py                # Main Streamlit application
â”œâ”€â”€ clip_model/           # Saved CLIP model files
â”œâ”€â”€ clip_processor/       # Saved CLIP processor files
â””â”€â”€ README.md             # You're here!
```
---

## ğŸ’¡ Future Improvements

* ğŸ”¤ Support dynamic caption generation using GPT-like models
* ğŸ—‚ï¸ Caption clustering and tag suggestions
* ğŸŒ Multilingual caption support
* ğŸ“± Mobile-friendly interface

---

## ğŸ§‘â€ğŸ’» Author

**Abhay Pratap Singh**
ğŸ“§ [LinkedIn](https://www.linkedin.com/in/abhayjadon/) | ğŸ’¼ AI & Data Science | ğŸ“ Final Year Engineer

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€“ feel free to use, modify, and share.

